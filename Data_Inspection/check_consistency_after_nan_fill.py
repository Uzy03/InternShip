#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
2009å¹´åˆä½µç”ºã‚’NaNã§åŸ‹ã‚ãŸå¾Œã®ç”ºä¸ä¸€è²«æ€§ç‡ã‚’è¨ˆç®—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np
from pathlib import Path
import re

def load_csv_file(file_path):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”ºä¸åã‚’æŠ½å‡º"""
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        town_names = []
        
        # æœ€åˆã®åˆ—ã‹ã‚‰ç”ºä¸åã‚’æŠ½å‡º
        for i, row in df.iterrows():
            town_name = str(row.iloc[0]) if len(row) > 0 else ""
            if (town_name and 
                not any(char.isdigit() for char in town_name) and
                not any(keyword in town_name for keyword in ['å¹´é½¢', 'åŒºåˆ†', 'è¨ˆ', 'ç”·', 'å¥³', 'å‚™è€ƒ', 'äººå£çµ±è¨ˆè¡¨', 'ç”ºä¸åˆ¥', 'ä¸€è¦§è¡¨', 'ç¾åœ¨', 'äºº', 'å£']) and
                len(town_name.strip()) > 1 and
                not town_name.strip().startswith('Column')):
                town_names.append(town_name.strip())
        
        return town_names
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
        return []

def analyze_town_consistency():
    """ç”ºä¸ä¸€è²«æ€§ã‚’åˆ†æ"""
    print("=== 2009å¹´åˆä½µç”ºã‚’NaNã§åŸ‹ã‚ãŸå¾Œã®ç”ºä¸ä¸€è²«æ€§åˆ†æ ===")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    csv_dir = Path("../Preprocessed_Data_csv")
    
    # NaNã§åŸ‹ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_files = list(csv_dir.glob("*_nan_filled.csv"))
    csv_files.sort()
    
    if not csv_files:
        print("âŒ NaNã§åŸ‹ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"âœ“ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”ºä¸åã‚’å–å¾—
    all_towns = set()
    file_towns = {}
    
    for csv_file in csv_files:
        print(f"èª­ã¿è¾¼ã¿ä¸­: {csv_file.name}")
        towns = load_csv_file(csv_file)
        file_towns[csv_file.name] = set(towns)
        all_towns.update(towns)
    
    print(f"\nâœ“ å…¨ç”ºä¸æ•°: {len(all_towns)}")
    
    # å„ç”ºä¸ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    town_consistency = {}
    total_files = len(csv_files)
    
    for town in all_towns:
        count = sum(1 for towns in file_towns.values() if town in towns)
        town_consistency[town] = count
    
    # ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸ï¼ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºç¾ï¼‰ã‚’ç‰¹å®š
    consistent_towns = [town for town, count in town_consistency.items() if count == total_files]
    inconsistent_towns = [town for town, count in town_consistency.items() if count < total_files]
    
    # ä¸€è²«æ€§ç‡ã‚’è¨ˆç®—
    consistency_rate = (len(consistent_towns) / len(all_towns)) * 100
    
    print(f"\n=== åˆ†æçµæœ ===")
    print(f"å…¨ç”ºä¸æ•°: {len(all_towns)}")
    print(f"ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸æ•°: {len(consistent_towns)}")
    print(f"ä¸€è²«æ€§ã®ãªã„ç”ºä¸æ•°: {len(inconsistent_towns)}")
    print(f"ç”ºä¸ä¸€è²«æ€§ç‡: {consistency_rate:.1f}%")
    
    # ä¸€è²«æ€§ã®ãªã„ç”ºä¸ã®è©³ç´°
    if inconsistent_towns:
        print(f"\n=== ä¸€è²«æ€§ã®ãªã„ç”ºä¸ï¼ˆå‡ºç¾å›æ•°é †ï¼‰ ===")
        sorted_inconsistent = sorted(inconsistent_towns, key=lambda x: town_consistency[x], reverse=True)
        
        for town in sorted_inconsistent[:20]:  # ä¸Šä½20ä»¶ã‚’è¡¨ç¤º
            count = town_consistency[town]
            missing_files = [fname for fname, towns in file_towns.items() if town not in towns]
            print(f"{town}: {count}/{total_files}å›å‡ºç¾")
            if len(missing_files) <= 5:
                print(f"  æ¬ æå¹´åº¦: {', '.join(missing_files)}")
            else:
                print(f"  æ¬ æå¹´åº¦: {len(missing_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # çµæœã‚’ä¿å­˜
    output_dir = Path("../Preprocessed_Data_csv")
    
    # ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸ãƒªã‚¹ãƒˆ
    consistent_file = output_dir / "consistent_towns_after_nan_fill.txt"
    with open(consistent_file, 'w', encoding='utf-8') as f:
        f.write("=== 2009å¹´åˆä½µç”ºã‚’NaNã§åŸ‹ã‚ãŸå¾Œã®ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸ ===\n")
        f.write(f"ä¸€è²«æ€§ç‡: {consistency_rate:.1f}%\n")
        f.write(f"ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸æ•°: {len(consistent_towns)}\n")
        f.write(f"å…¨ç”ºä¸æ•°: {len(all_towns)}\n\n")
        for town in sorted(consistent_towns):
            f.write(f"{town}\n")
    
    # ä¸€è²«æ€§åˆ†æçµæœ
    analysis_file = output_dir / "town_consistency_after_nan_fill.csv"
    analysis_data = []
    for town, count in town_consistency.items():
        missing_files = [fname for fname, towns in file_towns.items() if town not in towns]
        analysis_data.append({
            'ç”ºä¸å': town,
            'å‡ºç¾å›æ•°': count,
            'å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°': total_files,
            'ä¸€è²«æ€§': count == total_files,
            'æ¬ æãƒ•ã‚¡ã‚¤ãƒ«æ•°': len(missing_files),
            'æ¬ æãƒ•ã‚¡ã‚¤ãƒ«': ', '.join(missing_files) if len(missing_files) <= 3 else f"{len(missing_files)}ãƒ•ã‚¡ã‚¤ãƒ«"
        })
    
    analysis_df = pd.DataFrame(analysis_data)
    analysis_df.to_csv(analysis_file, index=False, encoding='utf-8-sig')
    
    print(f"\n=== çµæœä¿å­˜å®Œäº† ===")
    print(f"âœ“ ä¸€è²«æ€§ã®ã‚ã‚‹ç”ºä¸ãƒªã‚¹ãƒˆ: {consistent_file}")
    print(f"âœ“ è©³ç´°åˆ†æçµæœ: {analysis_file}")
    
    return consistency_rate, consistent_towns, all_towns

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    consistency_rate, consistent_towns, all_towns = analyze_town_consistency()
    
    if consistency_rate > 80:
        print(f"\nğŸ‰ ç´ æ™´ã‚‰ã—ã„ï¼ç”ºä¸ä¸€è²«æ€§ç‡ãŒ{consistency_rate:.1f}%ã«é”ã—ã¾ã—ãŸï¼")
    elif consistency_rate > 60:
        print(f"\nğŸ‘ è‰¯å¥½ãªçµæœã§ã™ï¼ç”ºä¸ä¸€è²«æ€§ç‡ãŒ{consistency_rate:.1f}%ã§ã™ã€‚")
    else:
        print(f"\nâš ï¸  ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚ç¾åœ¨ã®ä¸€è²«æ€§ç‡: {consistency_rate:.1f}%")

if __name__ == "__main__":
    main()
