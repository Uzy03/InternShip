# -*- coding: utf-8 -*-
"""
ã‚·ãƒ³ãƒ—ãƒ«äººå£äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
ç”ºä¸ã€ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã€åŠ¹æœæ–¹å‘ã®ã¿ã‚’é¸æŠã—ã¦äºˆæ¸¬å®Ÿè¡Œ
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
from pathlib import Path
import sys
import os
from typing import Dict, List, Any

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(__file__))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'layer5'))

# Layer5ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from scenario_to_events import scenario_to_events  # pyright: ignore[reportMissingImports]
    from prepare_baseline import prepare_baseline
    from build_future_features import build_future_features
    from forecast_service import forecast_population, run_scenario
    from scenario_with_learned_intensity import LearnedScenarioGenerator
except ImportError as e:
    st.error(f"Layer5ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚·ãƒ³ãƒ—ãƒ«äººå£äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ˜ï¸ ã‚·ãƒ³ãƒ—ãƒ«äººå£äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ç”ºä¸ã€ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã€åŠ¹æœæ–¹å‘ã‚’é¸æŠã—ã¦äººå£äºˆæ¸¬ã‚’å®Ÿè¡Œ")

# ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ¼ãƒ‰é¸æŠ
view_mode = st.radio(
    "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
    ["å˜ä¸€ç”ºä¸äºˆæ¸¬", "å…¨åœ°åŸŸè¡¨ç¤º"],
    horizontal=True
)

st.markdown("---")

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
@st.cache_data
def load_metadata():
    """åˆ©ç”¨å¯èƒ½ãªç”ºä¸ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    try:
        features_path = Path("../../data/processed/features_panel.csv")
        if not features_path.exists():
            features_path = Path("../data/processed/features_panel.csv")
        
        if not features_path.exists():
            st.error(f"features_panel.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {features_path}")
            return []
        
        df = pd.read_csv(features_path, usecols=["town"]).drop_duplicates()
        towns = sorted(df["town"].unique().tolist())
        
        return towns
    except Exception as e:
        st.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return []

towns = load_metadata()

if not towns:
    st.error("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

# å…¨åœ°åŸŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬é–¢æ•°
@st.cache_data
def run_all_towns_realtime_prediction(event_town: str, event_type: str, effect_direction: str, base_year: int = 2025, horizons: list = [1, 2, 3]):
    """æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã§å…¨ç”ºä¸ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    try:
        # åˆ©ç”¨å¯èƒ½ãªç”ºä¸ãƒªã‚¹ãƒˆã‚’å–å¾—
        features_path = Path("../../data/processed/features_panel.csv")
        if not features_path.exists():
            features_path = Path("../data/processed/features_panel.csv")
        
        if not features_path.exists():
            st.error(f"features_panel.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {features_path}")
            return None
        
        df = pd.read_csv(features_path, usecols=["town"]).drop_duplicates()
        all_towns = sorted(df["town"].unique().tolist())
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœ€åˆã®10ç”ºä¸ã®ã¿ã§ãƒ†ã‚¹ãƒˆï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        # if len(all_towns) > 10:
        #     st.warning(f"ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®10ç”ºä¸ã®ã¿ã§ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼ˆå…¨{len(all_towns)}ç”ºä¸ä¸­ï¼‰")
        #     all_towns = all_towns[:10]
        
        # å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚‰ãªã„ç”ºä¸ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        missing_features_count = 0
        max_missing_features = 5  # æœ€å¤§5ç”ºä¸ã¾ã§è­¦å‘Šã‚’è¡¨ç¤º
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        baseline_path = Path("../../data/processed/l5_baseline.csv")
        if not baseline_path.exists():
            baseline_path = Path("../data/processed/l5_baseline.csv")
        
        if not baseline_path.exists():
            st.error(f"l5_baseline.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {baseline_path}")
            return None
        
        baseline_df = pd.read_csv(baseline_path)
        
        # ã‚·ãƒŠãƒªã‚ªã‚’ä½œæˆ
        scenario = {
            "town": event_town,  # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸
            "base_year": base_year,
            "horizons": horizons,
            "events": [{
                "year_offset": 1,
                "event_type": event_type,
                "effect_direction": effect_direction,
                "confidence": 1.0,
                "intensity": 1.0,
                "lag_t": 1,
                "lag_t1": 1,
                "note": f"{event_type} ({effect_direction})"
            }],
            "macros": {},
            "manual_delta": {"h1": 0.0, "h2": 0.0, "h3": 0.0}
        }
        
        # å…¨ç”ºä¸ã®äºˆæ¸¬ã‚’å®Ÿè¡Œ
        st.info("å…¨ç”ºä¸ã®äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
        
        all_results = []
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®å°†æ¥ç‰¹å¾´ã‚’å…ˆã«æ§‹ç¯‰ï¼ˆä»–ã®ç”ºä¸ã§ã‚‚å‚ç…§ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
        if event_town in all_towns:
            st.info(f"ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ '{event_town}' ã®å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰ä¸­...")
            try:
                # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®ã‚·ãƒŠãƒªã‚ªã§å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰
                event_baseline = prepare_baseline(event_town, base_year)
                event_future_events = scenario_to_events(scenario)
                event_future_features = build_future_features(event_baseline, event_future_events, scenario)
                
                # å°†æ¥ç‰¹å¾´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                features_path = Path("../../data/processed/l5_future_features.csv")
                event_future_features.to_csv(features_path, index=False)
                st.success(f"ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ '{event_town}' ã®å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰å®Œäº†")
            except Exception as e:
                st.warning(f"ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®å°†æ¥ç‰¹å¾´æ§‹ç¯‰ã«å¤±æ•—: {e}")
        
        for i, town in enumerate(all_towns):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°é »åº¦ã‚’æ¸›ã‚‰ã™ï¼ˆ10ç”ºä¸ã”ã¨ï¼‰
            if i % 10 == 0 or i == len(all_towns) - 1:
                status_text.text(f"å‡¦ç†ä¸­: {town} ({i+1}/{len(all_towns)})")
                progress_bar.progress((i + 1) / len(all_towns))
            
            # å„ç”ºä¸ç”¨ã®ã‚·ãƒŠãƒªã‚ªã‚’ä½œæˆ
            if town == event_town:
                # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ï¼šã‚¤ãƒ™ãƒ³ãƒˆã‚ã‚Šã®ã‚·ãƒŠãƒªã‚ª
                town_scenario = {
                    "town": town,
                    "base_year": base_year,
                    "horizons": horizons,
                    "events": scenario["events"],
                    "macros": {},
                    "manual_delta": {"h1": 0.0, "h2": 0.0, "h3": 0.0}
                }
            else:
                # ãã®ä»–ã®ç”ºä¸ï¼šé€šå¸¸ã®äººå£äºˆæ¸¬ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãªã—ï¼‰
                town_scenario = {
                    "town": town,
                    "base_year": base_year,
                    "horizons": horizons,
                    "events": [],  # ã‚¤ãƒ™ãƒ³ãƒˆãªã—
                    "macros": {},
                    "manual_delta": {"h1": 0.0, "h2": 0.0, "h3": 0.0}
                }
            
            # ãƒ™ãƒ¼ã‚¹äººå£ã‚’å–å¾—
            town_baseline = baseline_df[baseline_df["town"] == town]
            if not town_baseline.empty and "pop_total" in town_baseline.columns:
                town_scenario["base_population"] = float(town_baseline["pop_total"].iloc[0])
            else:
                town_scenario["base_population"] = 0.0
            
            try:
                # äºˆæ¸¬å®Ÿè¡Œï¼ˆãƒ­ã‚°ã‚’å‰Šæ¸›ï¼‰
                if town != event_town:
                    # ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã—ã¦ã„ãªã„ç”ºä¸ã®å ´åˆã¯ã€å€‹åˆ¥ã«å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰ã—ã¦ã‹ã‚‰äºˆæ¸¬
                    try:
                        # å„ç”ºä¸ç”¨ã®ã‚·ãƒŠãƒªã‚ªã§å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰
                        individual_scenario = {
                            "town": town,
                            "base_year": base_year,
                            "horizons": horizons,
                            "events": [],  # ã‚¤ãƒ™ãƒ³ãƒˆãªã—
                            "macros": {},
                            "manual_delta": {"h1": 0.0, "h2": 0.0, "h3": 0.0}
                        }
                        
                        # å€‹åˆ¥ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                        individual_baseline = prepare_baseline(town, base_year)
                        
                        # å€‹åˆ¥ã®å°†æ¥ã‚¤ãƒ™ãƒ³ãƒˆè¡Œåˆ—ã‚’ç”Ÿæˆï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãªã—ï¼‰
                        individual_future_events = scenario_to_events(individual_scenario)
                        
                        # å€‹åˆ¥ã®å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰
                        individual_future_features = build_future_features(
                            individual_baseline, individual_future_events, individual_scenario
                        )
                        
                        # ä¸€æ™‚çš„ã«å°†æ¥ç‰¹å¾´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ï¼ˆforecast_populationãŒèª­ã¿è¾¼ã‚€ãŸã‚ï¼‰
                        temp_features_path = Path("../../data/processed/l5_future_features.csv")
                        individual_future_features.to_csv(temp_features_path, index=False)
                        
                        # é€šå¸¸ã®äººå£äºˆæ¸¬ã‚’å®Ÿè¡Œ
                        result = forecast_population(
                            town=town,
                            base_year=base_year,
                            horizons=horizons,
                            base_population=town_scenario["base_population"],
                            debug_output_dir=None,
                            manual_add_by_h={1: 0.0, 2: 0.0, 3: 0.0},
                            apply_event_to_prediction=False  # ã‚¤ãƒ™ãƒ³ãƒˆãªã—ã®é€šå¸¸äºˆæ¸¬
                        )
                        
                    except Exception as individual_error:
                        # å€‹åˆ¥æ§‹ç¯‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€åŸºæœ¬äºˆæ¸¬ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        if missing_features_count <= max_missing_features:
                            st.warning(f"ç”ºä¸ '{town}' ã®å€‹åˆ¥ç‰¹å¾´æ§‹ç¯‰ã«å¤±æ•—ã€åŸºæœ¬äºˆæ¸¬ã‚’å®Ÿè¡Œ: {individual_error}")
                        
                        result = forecast_population(
                            town=town,
                            base_year=base_year,
                            horizons=horizons,
                            base_population=town_scenario["base_population"],
                            debug_output_dir=None,
                            manual_add_by_h={1: 0.0, 2: 0.0, 3: 0.0},
                            apply_event_to_prediction=False
                        )
                else:
                    # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã¯æ—¢ã«æ§‹ç¯‰ã•ã‚ŒãŸå°†æ¥ç‰¹å¾´ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬
                    result = forecast_population(
                        town=town,
                        base_year=base_year,
                        horizons=horizons,
                        base_population=town_scenario["base_population"],
                        debug_output_dir=None,
                        manual_add_by_h={1: 0.0, 2: 0.0, 3: 0.0},
                        apply_event_to_prediction=True  # ã‚¤ãƒ™ãƒ³ãƒˆã‚ã‚Šã®äºˆæ¸¬
                    )
                
                # çµæœã®æ¤œè¨¼
                if result is None or "path" not in result:
                    st.warning(f"ç”ºä¸ '{town}' ã®äºˆæ¸¬çµæœãŒç„¡åŠ¹ã§ã™ (result: {result})")
                    # ç„¡åŠ¹ãªçµæœã‚‚å«ã‚ã‚‹ï¼ˆNaNãªã©ã§ï¼‰
                    for h_val in horizons:
                        all_results.append({
                            "town": town,
                            "baseline_year": base_year,
                            "year": base_year + h_val,
                            "h": h_val,
                            "delta": float('nan'),
                            "pop": float('nan'),
                            "exp": float('nan'),
                            "macro": float('nan'),
                            "inertia": float('nan'),
                            "other": float('nan'),
                            "pi_delta_low": float('nan'),
                            "pi_delta_high": float('nan'),
                            "pi_pop_low": float('nan'),
                            "pi_pop_high": float('nan'),
                            "is_event_town": (town == event_town),
                        })
                    continue
                
                # çµæœã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆforecast_populationã¯"path"ã‚­ãƒ¼ã‚’è¿”ã™ï¼‰
                for entry in result["path"]:
                    row = {
                        "town": result["town"],
                        "baseline_year": result["baseline_year"],
                        "year": entry["year"],
                        "h": entry["year"] - result["baseline_year"],
                        "delta": entry["delta_hat"],
                        "pop": entry["pop_hat"],
                        "exp": entry["contrib"]["exp"],
                        "macro": entry["contrib"]["macro"],
                        "inertia": entry["contrib"]["inertia"],
                        "other": entry["contrib"]["other"],
                        "pi_delta_low": entry["pi95_delta"][0] if isinstance(entry["pi95_delta"], list) else entry["pi95_delta"],
                        "pi_delta_high": entry["pi95_delta"][1] if isinstance(entry["pi95_delta"], list) else entry["pi95_delta"],
                        "pi_pop_low": entry["pi95_pop"][0] if isinstance(entry["pi95_pop"], list) else entry["pi95_pop"],
                        "pi_pop_high": entry["pi95_pop"][1] if isinstance(entry["pi95_pop"], list) else entry["pi95_pop"],
                        "is_event_town": (town == event_town),  # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã‹ã©ã†ã‹
                    }
                    all_results.append(row)
                    
            except Exception as e:
                error_msg = str(e)
                if "å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in error_msg:
                    missing_features_count += 1
                    if missing_features_count <= max_missing_features:
                        st.warning(f"ç”ºä¸ '{town}' ã®å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŸºæœ¬äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
                    elif missing_features_count == max_missing_features + 1:
                        st.warning(f"ä»–ã«ã‚‚å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚‰ãªã„ç”ºä¸ãŒã‚ã‚Šã¾ã™ãŒã€è­¦å‘Šè¡¨ç¤ºã‚’åˆ¶é™ã—ã¾ã™ã€‚")
                    
                    # å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆãªã—ã®åŸºæœ¬äºˆæ¸¬ã‚’å®Ÿè¡Œ
                    try:
                        basic_scenario = {
                            "town": town,
                            "base_year": base_year,
                            "horizons": horizons,
                            "events": [],  # ã‚¤ãƒ™ãƒ³ãƒˆãªã—
                            "macros": {},
                            "manual_delta": {"h1": 0.0, "h2": 0.0, "h3": 0.0},
                            "base_population": town_scenario["base_population"]
                        }
                        result = run_scenario(basic_scenario, out_path=None)
                        
                        if result and "results" in result:
                            # åŸºæœ¬äºˆæ¸¬ã®çµæœã‚’ä½¿ç”¨
                            for entry in result["results"]:
                                row = {
                                    "town": result["town"],
                                    "baseline_year": result["baseline_year"],
                                    "year": entry["year"],
                                    "h": entry["year"] - result["baseline_year"],
                                    "delta": entry["delta"],
                                    "pop": entry["pop"],
                                    "exp": entry["contrib"]["exp"],
                                    "macro": entry["contrib"]["macro"],
                                    "inertia": entry["contrib"]["inertia"],
                                    "other": entry["contrib"]["other"],
                                    "pi_delta_low": entry["pi"]["delta_low"],
                                    "pi_delta_high": entry["pi"]["delta_high"],
                                    "pi_pop_low": entry["pi"]["pop_low"],
                                    "pi_pop_high": entry["pi"]["pop_high"],
                                    "is_event_town": (town == event_town),
                                }
                                all_results.append(row)
                            continue
                    except Exception as basic_error:
                        if missing_features_count <= max_missing_features:
                            st.warning(f"ç”ºä¸ '{town}' ã®åŸºæœ¬äºˆæ¸¬ã‚‚å¤±æ•—")
                        # åŸºæœ¬äºˆæ¸¬ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã€NaNã§åŸ‹ã‚ã‚‹
                        for h_val in horizons:
                            all_results.append({
                                "town": town,
                                "baseline_year": base_year,
                                "year": base_year + h_val,
                                "h": h_val,
                                "delta": float('nan'),
                                "pop": float('nan'),
                                "exp": float('nan'),
                                "macro": float('nan'),
                                "inertia": float('nan'),
                                "other": float('nan'),
                                "pi_delta_low": float('nan'),
                                "pi_delta_high": float('nan'),
                                "pi_pop_low": float('nan'),
                                "pi_pop_high": float('nan'),
                                "is_event_town": (town == event_town),
                            })
                        continue
                
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                if missing_features_count <= max_missing_features:
                    st.warning(f"ç”ºä¸ '{town}' ã®äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸç”ºä¸ã‚‚çµæœã«å«ã‚ã‚‹ï¼ˆNaNãªã©ã§ï¼‰
                for h_val in horizons:
                    all_results.append({
                        "town": town,
                        "baseline_year": base_year,
                        "year": base_year + h_val,
                        "h": h_val,
                        "delta": float('nan'),
                        "pop": float('nan'),
                        "exp": float('nan'),
                        "macro": float('nan'),
                        "inertia": float('nan'),
                        "other": float('nan'),
                        "pi_delta_low": float('nan'),
                        "pi_delta_high": float('nan'),
                        "pi_pop_low": float('nan'),
                        "pi_pop_high": float('nan'),
                        "is_event_town": (town == event_town),
                    })
                continue
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        progress_bar.empty()
        status_text.empty()
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        if missing_features_count > 0:
            st.info(f"ğŸ“Š å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸç”ºä¸: {missing_features_count}ç”ºä¸ï¼ˆåŸºæœ¬äºˆæ¸¬ã§ä»£æ›¿ï¼‰")
            st.warning("âš ï¸ å°†æ¥ç‰¹å¾´ãŒè¦‹ã¤ã‹ã‚‰ãªã„ç”ºä¸ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆåŠ¹æœãªã—ã®åŸºæœ¬äºˆæ¸¬ï¼ˆäººå£å¤‰åŒ–=0ï¼‰ã§å‡¦ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        
        if not all_results:
            st.error("äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # DataFrameã«å¤‰æ›
        result_df = pd.DataFrame(all_results)
        
        # é‡å¿ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°çµåˆ
        centroids_path = Path("../../data/interim/centroids.csv")
        if not centroids_path.exists():
            centroids_path = Path("../data/interim/centroids.csv")
        
        if centroids_path.exists():
            try:
                centroids_df = pd.read_csv(centroids_path, usecols=["town", "lat", "lon"])
                result_df = pd.merge(result_df, centroids_df, on="town", how="left")
            except Exception as e:
                st.warning(f"é‡å¿ƒãƒ‡ãƒ¼ã‚¿ã®çµåˆã«å¤±æ•—: {e}")
        
        return result_df
        
    except Exception as e:
        st.error(f"å…¨åœ°åŸŸäºˆæ¸¬ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# å…¨åœ°åŸŸè¡¨ç¤ºã®å ´åˆ
if view_mode == "å…¨åœ°åŸŸè¡¨ç¤º":
    st.header("ğŸŒ å…¨åœ°åŸŸè¡¨ç¤º - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬")
    
    # ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®šUI
    st.subheader("ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®é¸æŠ
        event_town = st.selectbox(
            "ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸",
            towns,
            index=0,
            help="ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã™ã‚‹ç”ºä¸ã‚’é¸æŠ"
        )
    
    with col2:
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®é¸æŠ
        EVENT_TYPE_MAPPING = {
            "housing_inc": "ä½å®…ä¾›çµ¦ã®å¢—åŠ ï¼ˆç«£å·¥ï¼‰",
            "housing_dec": "ä½å®…ã®æ¸›å°‘ãƒ»å–ªå¤±",
            "commercial_inc": "å•†æ¥­æ–½è¨­ã®å¢—åŠ ", 
            "transit_inc": "äº¤é€šåˆ©ä¾¿ã®å‘ä¸Š",
            "transit_dec": "äº¤é€šåˆ©ä¾¿ã®ä½ä¸‹",
            "public_edu_medical_inc": "å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®å¢—åŠ ",
            "public_edu_medical_dec": "å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®æ¸›å°‘",
            "employment_inc": "é›‡ç”¨æ©Ÿä¼šã®å¢—åŠ ",
            "employment_dec": "é›‡ç”¨æ©Ÿä¼šã®æ¸›å°‘",
            "disaster_inc": "ç½å®³è¢«å®³ãƒ»ãƒªã‚¹ã‚¯ã®å¢—åŠ ",
            "disaster_dec": "ç½å®³ãƒªã‚¹ã‚¯ã®ä½ä¸‹ï¼ˆé˜²ç½æ•´å‚™ï¼‰"
        }
        
        event_type_display = st.selectbox(
            "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—",
            list(EVENT_TYPE_MAPPING.values()),
            help="äººå£ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ç¨®é¡ã‚’é¸æŠ"
        )
        
        # è¡¨ç¤ºåã‹ã‚‰å†…éƒ¨ã‚­ãƒ¼ã«å¤‰æ›
        event_type_full = [k for k, v in EVENT_TYPE_MAPPING.items() if v == event_type_display][0]
        
        # å†…éƒ¨ã‚­ãƒ¼ã‹ã‚‰event_typeã¨effect_directionã«åˆ†å‰²
        if event_type_full.endswith("_inc"):
            event_type = event_type_full[:-4]
            effect_direction = "increase"
        elif event_type_full.endswith("_dec"):
            event_type = event_type_full[:-4]
            effect_direction = "decrease"
        else:
            event_type = event_type_full
            effect_direction = "increase"
    
    # äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ å…¨åœ°åŸŸäºˆæ¸¬å®Ÿè¡Œ", type="primary", use_container_width=True):
        with st.spinner("å…¨ç”ºä¸ã®äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
            forecast_df = run_all_towns_realtime_prediction(
                event_town=event_town,
                event_type=event_type,
                effect_direction=effect_direction
            )
    
    # äºˆæ¸¬çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    if 'forecast_df' in locals() and forecast_df is not None:
        st.success(f"âœ… äºˆæ¸¬å®Œäº†ï¼{len(forecast_df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
        st.subheader("ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸")
        event_town_data = forecast_df[forecast_df['is_event_town'] == True]
        if not event_town_data.empty:
            st.info(f"**{event_town}** ã§ **{event_type_display}** ãŒç™ºç”Ÿ")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è¨­å®š
        st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»è¡¨ç¤ºè¨­å®š")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # å¹´ã‚»ãƒ¬ã‚¯ã‚¿
            available_years = sorted(forecast_df['year'].unique())
            selected_year = st.selectbox("å¹´ã‚’é¸æŠ", available_years, index=len(available_years)-1)
        
        with col2:
            # æŒ‡æ¨™ã‚»ãƒ¬ã‚¯ã‚¿
            metric_options = {
                "delta": "Î”äººå£",
                "pop": "äººå£",
                "exp": "æœŸå¾…åŠ¹æœ",
                "macro": "ãƒã‚¯ãƒ­",
                "inertia": "æ…£æ€§",
                "other": "ãã®ä»–"
            }
            selected_metric = st.selectbox("æŒ‡æ¨™ã‚’é¸æŠ", list(metric_options.keys()), 
                                         format_func=lambda x: metric_options[x])
        
        with col3:
            # ç”ºä¸æ¤œç´¢
            search_term = st.text_input("ç”ºä¸åã§æ¤œç´¢", placeholder="ç”ºä¸åã®ä¸€éƒ¨ã‚’å…¥åŠ›")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_df = forecast_df[forecast_df['year'] == selected_year].copy()
        
        if search_term:
            filtered_df = filtered_df[filtered_df['town'].str.contains(search_term, case=False, na=False)]
        
        # ã‚½ãƒ¼ãƒˆè¨­å®š
        sort_options = {
            "delta_desc": "Î”äººå£ï¼ˆé™é †ï¼‰",
            "delta_asc": "Î”äººå£ï¼ˆæ˜‡é †ï¼‰",
            "pop_desc": "äººå£ï¼ˆé™é †ï¼‰",
            "pop_asc": "äººå£ï¼ˆæ˜‡é †ï¼‰",
            "town_asc": "ç”ºä¸åï¼ˆæ˜‡é †ï¼‰"
        }
        
        sort_option = st.selectbox("ã‚½ãƒ¼ãƒˆé †", list(sort_options.keys()), 
                                  format_func=lambda x: sort_options[x])
        
        if sort_option == "delta_desc":
            filtered_df = filtered_df.sort_values('delta', ascending=False)
        elif sort_option == "delta_asc":
            filtered_df = filtered_df.sort_values('delta', ascending=True)
        elif sort_option == "pop_desc":
            filtered_df = filtered_df.sort_values('pop', ascending=False)
        elif sort_option == "pop_asc":
            filtered_df = filtered_df.sort_values('pop', ascending=True)
        elif sort_option == "town_asc":
            filtered_df = filtered_df.sort_values('town', ascending=True)
        
        # çµ±è¨ˆæƒ…å ±
        st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è¡¨ç¤ºç”ºä¸æ•°", len(filtered_df))
        
        with col2:
            avg_delta = filtered_df['delta'].mean()
            st.metric("å¹³å‡Î”äººå£", f"{avg_delta:.1f}äºº")
        
        with col3:
            max_delta = filtered_df['delta'].max()
            st.metric("æœ€å¤§Î”äººå£", f"{max_delta:.1f}äºº")
        
        with col4:
            min_delta = filtered_df['delta'].min()
            st.metric("æœ€å°Î”äººå£", f"{min_delta:.1f}äºº")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®è©³ç´°è¡¨ç¤º
        if not event_town_data.empty:
            st.subheader("ğŸ¯ ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã®è©³ç´°")
            event_year_data = event_town_data[event_town_data['year'] == selected_year]
            if not event_year_data.empty:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("äººå£", f"{event_year_data['pop'].iloc[0]:.1f}äºº")
                with col2:
                    st.metric("Î”äººå£", f"{event_year_data['delta'].iloc[0]:.1f}äºº")
                with col3:
                    st.metric("æœŸå¾…åŠ¹æœ", f"{event_year_data['exp'].iloc[0]:.1f}äºº")
                with col4:
                    st.metric("ãã®ä»–", f"{event_year_data['other'].iloc[0]:.1f}äºº")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.subheader(f"ğŸ“Š {selected_year}å¹´ã®{metric_options[selected_metric]}ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        
        # è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ
        display_columns = ["town", "pop", "delta", "exp", "macro", "inertia", "other", "is_event_town"]
        
        # é‡å¿ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if "lat" in filtered_df.columns and "lon" in filtered_df.columns:
            display_columns.extend(["lat", "lon"])
        
        # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        column_mapping = {
            "town": "ç”ºä¸",
            "pop": "äººå£",
            "delta": "Î”äººå£",
            "exp": "æœŸå¾…åŠ¹æœ",
            "macro": "ãƒã‚¯ãƒ­",
            "inertia": "æ…£æ€§",
            "other": "ãã®ä»–",
            "is_event_town": "ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°",
            "lat": "ç·¯åº¦",
            "lon": "çµŒåº¦"
        }
        
        display_df = filtered_df[display_columns].copy()
        display_df = display_df.rename(columns=column_mapping)
        
        # æ•°å€¤åˆ—ã‚’ä¸¸ã‚ã‚‹
        numeric_columns = ["äººå£", "Î”äººå£", "æœŸå¾…åŠ¹æœ", "ãƒã‚¯ãƒ­", "æ…£æ€§", "ãã®ä»–"]
        for col in numeric_columns:
            if col in display_df.columns:
                display_df[col] = display_df[col].round(1)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        def highlight_event_town(row):
            if row['ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°']:
                return ['background-color: #ffeb3b'] * len(row)
            return [''] * len(row)
        
        styled_df = display_df.style.apply(highlight_event_town, axis=1)
        st.dataframe(styled_df, use_container_width=True)
        
        # ãƒãƒƒãƒ—è¡¨ç¤ºï¼ˆé‡å¿ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        if "lat" in filtered_df.columns and "lon" in filtered_df.columns:
            st.subheader("ğŸ—ºï¸ ç©ºé–“çš„å½±éŸ¿ã®å¯è¦–åŒ–")
            
            # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã¨ãã®ä»–ã®ç”ºä¸ã‚’åˆ†ã‘ã‚‹
            event_town_data = filtered_df[filtered_df['is_event_town'] == True]
            other_towns_data = filtered_df[filtered_df['is_event_town'] == False]
            
            fig_map = go.Figure()
            
            # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ï¼ˆå¤§ããã€èµ¤è‰²ã§è¡¨ç¤ºï¼‰
            if not event_town_data.empty:
                fig_map.add_trace(go.Scattermapbox(
                    lat=event_town_data['lat'],
                    lon=event_town_data['lon'],
                    mode='markers',
                    marker=dict(
                        size=30,
                        color='red',
                        opacity=0.9,
                        line=dict(width=3, color='darkred')
                    ),
                    text=event_town_data['town'] + '<br>Î”äººå£: ' + event_town_data['delta'].astype(str) + '<br>ã€ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°ã€‘',
                    hovertemplate='%{text}<extra></extra>',
                    name='ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°'
                ))
            
            # ãã®ä»–ã®ç”ºä¸ï¼ˆÎ”ã®å€¤ã«å¿œã˜ã¦è‰²ã¨ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼‰
            if not other_towns_data.empty:
                # è‰²ã®è¨­å®šï¼ˆÎ”ã®ç¬¦å·ã«åŸºã¥ãï¼‰
                colors = ['orange' if x > 0 else 'blue' for x in other_towns_data['delta']]
                sizes = [max(5, min(20, abs(x) / 10)) for x in other_towns_data['delta']]  # ã‚µã‚¤ã‚ºã‚’æ­£è¦åŒ–
                
                fig_map.add_trace(go.Scattermapbox(
                    lat=other_towns_data['lat'],
                    lon=other_towns_data['lon'],
                    mode='markers',
                    marker=dict(
                        size=sizes,
                        color=colors,
                        opacity=0.6,
                        line=dict(width=1, color='white')
                    ),
                    text=other_towns_data['town'] + '<br>Î”äººå£: ' + other_towns_data['delta'].astype(str),
                    hovertemplate='%{text}<extra></extra>',
                    name='ãã®ä»–ã®ç”ºä¸'
                ))
            
            # åœ°å›³ã®ä¸­å¿ƒã‚’ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç”ºä¸ã«è¨­å®š
            if not event_town_data.empty:
                center_lat = event_town_data['lat'].iloc[0]
                center_lon = event_town_data['lon'].iloc[0]
            else:
                center_lat = filtered_df['lat'].mean()
                center_lon = filtered_df['lon'].mean()
            
            fig_map.update_layout(
                mapbox=dict(
                    style="open-street-map",
                    center=dict(lat=center_lat, lon=center_lon),
                    zoom=12
                ),
                height=600,
                title=f"{selected_year}å¹´ã®ç©ºé–“çš„å½±éŸ¿åˆ†å¸ƒï¼ˆèµ¤: ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿåœ°ã€ã‚ªãƒ¬ãƒ³ã‚¸: æ­£ã®å½±éŸ¿ã€é’: è² ã®å½±éŸ¿ï¼‰"
            )
            
            st.plotly_chart(fig_map, use_container_width=True)
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤º
        st.subheader("ğŸ“ˆ åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ")
        
        fig_hist = go.Figure()
        
        fig_hist.add_trace(go.Histogram(
            x=filtered_df[selected_metric],
            nbinsx=30,
            name=metric_options[selected_metric],
            marker_color='lightblue',
            opacity=0.7
        ))
        
        fig_hist.update_layout(
            title=f"{selected_year}å¹´ã®{metric_options[selected_metric]}åˆ†å¸ƒ",
            xaxis_title=metric_options[selected_metric],
            yaxis_title="ç”ºä¸æ•°",
            height=400
        )
        
        st.plotly_chart(fig_hist, use_container_width=True)
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv_data = display_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"forecast_all_{event_town}_{event_type}_{selected_year}.csv",
            mime="text/csv",
            type="secondary",
            use_container_width=True
        )
    
    else:
        st.info("ğŸ‘† ä¸Šè¨˜ã®è¨­å®šã§ã€Œå…¨åœ°åŸŸäºˆæ¸¬å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

else:
    # å˜ä¸€ç”ºä¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼‰
    st.header("ğŸ˜ï¸ å˜ä¸€ç”ºä¸äºˆæ¸¬")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚·ãƒŠãƒªã‚ªè¨­å®šï¼ˆå˜ä¸€ç”ºä¸äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    if view_mode == "å˜ä¸€ç”ºä¸äºˆæ¸¬":
        st.sidebar.header("ğŸ¯ ã‚·ãƒŠãƒªã‚ªè¨­å®š")

        # åŸºæœ¬è¨­å®š
        st.sidebar.subheader("åŸºæœ¬è¨­å®š")
town = st.sidebar.selectbox("ç”ºä¸", towns, index=0, help="äºˆæ¸¬å¯¾è±¡ã®ç”ºä¸ã‚’é¸æŠ")

# ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
st.sidebar.subheader("ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š")

# ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå†…éƒ¨ã‚­ãƒ¼ â†’ è¡¨ç¤ºåï¼‰
# effects_coefficients_rate.csvã«å­˜åœ¨ã™ã‚‹11å€‹ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿
EVENT_TYPE_MAPPING = {
    "housing_inc": "ä½å®…ä¾›çµ¦ã®å¢—åŠ ï¼ˆç«£å·¥ï¼‰",
    "housing_dec": "ä½å®…ã®æ¸›å°‘ãƒ»å–ªå¤±",
    "commercial_inc": "å•†æ¥­æ–½è¨­ã®å¢—åŠ ", 
    "transit_inc": "äº¤é€šåˆ©ä¾¿ã®å‘ä¸Š",
    "transit_dec": "äº¤é€šåˆ©ä¾¿ã®ä½ä¸‹",
    "public_edu_medical_inc": "å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®å¢—åŠ ",
    "public_edu_medical_dec": "å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®æ¸›å°‘",
    "employment_inc": "é›‡ç”¨æ©Ÿä¼šã®å¢—åŠ ",
    "employment_dec": "é›‡ç”¨æ©Ÿä¼šã®æ¸›å°‘",
    "disaster_inc": "ç½å®³è¢«å®³ãƒ»ãƒªã‚¹ã‚¯ã®å¢—åŠ ",
    "disaster_dec": "ç½å®³ãƒªã‚¹ã‚¯ã®ä½ä¸‹ï¼ˆé˜²ç½æ•´å‚™ï¼‰"
}

# ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®é¸æŠï¼ˆè¡¨ç¤ºåã§é¸æŠã€å†…éƒ¨ã‚­ãƒ¼ã§å‡¦ç†ï¼‰
event_type_display = st.sidebar.selectbox(
    "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—", 
    list(EVENT_TYPE_MAPPING.values()),
    help="äººå£ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ç¨®é¡ã‚’é¸æŠ"
)

# è¡¨ç¤ºåã‹ã‚‰å†…éƒ¨ã‚­ãƒ¼ã«å¤‰æ›
event_type_full = [k for k, v in EVENT_TYPE_MAPPING.items() if v == event_type_display][0]

# å†…éƒ¨ã‚­ãƒ¼ã‹ã‚‰event_typeã¨effect_directionã«åˆ†å‰²
if event_type_full.endswith("_inc"):
    event_type = event_type_full[:-4]  # "_inc"ã‚’é™¤å»
    effect_direction = "increase"
elif event_type_full.endswith("_dec"):
    event_type = event_type_full[:-4]  # "_dec"ã‚’é™¤å»
    effect_direction = "decrease"
else:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé€šå¸¸ã¯ç™ºç”Ÿã—ãªã„ï¼‰
    event_type = event_type_full
    effect_direction = "increase"

# å¼·åº¦è¨­å®šï¼ˆå­¦ç¿’ã•ã‚ŒãŸå¼·åº¦ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä½¿ç”¨ï¼‰
use_learned_intensity = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å­¦ç¿’ã•ã‚ŒãŸå¼·åº¦ã‚’ä½¿ç”¨

# æ‰‹å‹•åŠ ç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå›ºå®šå€¤ï¼‰
st.sidebar.subheader("æ‰‹å‹•åŠ ç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
st.sidebar.info("æ‰‹å‹•åŠ ç®—ã¯0ã«å›ºå®šã•ã‚Œã¦ã„ã¾ã™ï¼ˆç´”ç²‹ãªã‚¤ãƒ™ãƒ³ãƒˆåŠ¹æœã‚’ç¢ºèªã™ã‚‹ãŸã‚ï¼‰")
h1 = 0.0
h2 = 0.0
h3 = 0.0

# è¡¨ç¤ºç”¨ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
st.sidebar.text_input("h1 (2026å¹´) æ‰‹å‹•åŠ ç®—", value="0.0", disabled=True, help="2026å¹´ã®æ‰‹å‹•åŠ ç®—äººæ•°")
st.sidebar.text_input("h2 (2027å¹´) æ‰‹å‹•åŠ ç®—", value="0.0", disabled=True, help="2027å¹´ã®æ‰‹å‹•åŠ ç®—äººæ•°")
st.sidebar.text_input("h3 (2028å¹´) æ‰‹å‹•åŠ ç®—", value="0.0", disabled=True, help="2028å¹´ã®æ‰‹å‹•åŠ ç®—äººæ•°")

# å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
st.sidebar.subheader("å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
st.sidebar.info("""
**å›ºå®šè¨­å®š:**
- åŸºæº–å¹´: 2025
- äºˆæ¸¬æœŸé–“: [1, 2, 3]å¹´å…ˆ
- å¹´ã‚ªãƒ•ã‚»ãƒƒãƒˆ: 1å¹´ï¼ˆç¿Œå¹´ï¼‰
- ä¿¡é ¼åº¦: 1.0
- å¼·åº¦: 1.0
- ãƒ©ã‚°åŠ¹æœ: å½“å¹´ãƒ»ç¿Œå¹´ä¸¡æ–¹
""")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ç¾åœ¨ã®ã‚·ãƒŠãƒªã‚ªçŠ¶æ³
st.header("ğŸ“‹ ç¾åœ¨ã®ã‚·ãƒŠãƒªã‚ª")

# ã‚·ãƒŠãƒªã‚ªæ¦‚è¦ã‚’è¡¨ç¤º
col1, col2 = st.columns(2)
with col1:
    st.metric("é¸æŠç”ºä¸", town)
with col2:
    st.metric("ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—", event_type_display)

# ã‚·ãƒŠãƒªã‚ªè©³ç´°
st.subheader("ğŸ“ ã‚·ãƒŠãƒªã‚ªè©³ç´°")

# ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®è©³ç´°èª¬æ˜
EVENT_DESCRIPTIONS = {
    "housing": {
        "increase": "æ–°è¦ã®ãƒãƒ³ã‚·ãƒ§ãƒ³ãƒ»ã‚¢ãƒ‘ãƒ¼ãƒˆãƒ»æˆ¸å»ºã¦ãŒä¾›çµ¦ã•ã‚Œã‚‹ï¼ˆåˆ†è­²ãƒãƒ³ã‚·ãƒ§ãƒ³ç«£å·¥ã€å›£åœ°å…¥å±…ã€å®…åœ°é€ æˆå¾Œã®å…¥å±…ï¼‰",
        "decrease": "ä½å®…ã®è§£ä½“ãƒ»ç”¨é€”è»¢ç”¨ãƒ»ç©ºãå®¶åŒ–ãªã©ã§å®Ÿè³ªçš„ãªä¾›çµ¦ãŒæ¸›ã‚‹ï¼ˆä¸€æ–‰è§£ä½“ã€è€æœ½åŒ–ã§æœªåˆ©ç”¨åŒ–ã€ä½å®…â†’é§è»Šå ´è»¢ç”¨ï¼‰"
    },
    "commercial": {
        "increase": "åº—èˆ—ãƒ»ãƒ¢ãƒ¼ãƒ«ãªã©å•†æ¥­é›†ç©ãŒæ‹¡å¤§ï¼ˆå¤§å‹å•†æ¥­æ–½è¨­é–‹æ¥­ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼æ–°è¨­ã€å•†åº—é›†ç©ï¼‰",
        "decrease": "å•†æ¥­æ–½è¨­ã®æ’¤é€€ãƒ»é–‰é–ã§é›†ç©ãŒæ¸›å°‘ï¼ˆåº—èˆ—é–‰é–ã€ãƒ¢ãƒ¼ãƒ«æ’¤é€€ï¼‰"
    },
    "transit": {
        "increase": "æ–°é§…ãƒ»å¢—ä¾¿ãƒ»é“è·¯æ•´å‚™ãªã©ã§ã‚¢ã‚¯ã‚»ã‚¹ãŒæ”¹å–„ï¼ˆæ–°é§…é–‹æ¥­ã€ãƒã‚¹å¢—ä¾¿ã€ICä¾›ç”¨ï¼‰",
        "decrease": "è·¯ç·šæ’¤é€€ãƒ»æ¸›ä¾¿ç­‰ã§ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‚ªåŒ–ï¼ˆãƒã‚¹æ¸›ä¾¿ã€è·¯ç·šå»ƒæ­¢ï¼‰"
    },
    "policy_boundary": {
        "increase": "æ”¿ç­–å¢ƒç•Œã®å¤‰æ›´ã«ã‚ˆã‚ŠåŒºåŸŸãŒæ‹¡å¤§",
        "decrease": "æ”¿ç­–å¢ƒç•Œã®å¤‰æ›´ã«ã‚ˆã‚ŠåŒºåŸŸãŒç¸®å°"
    },
    "public_edu_medical": {
        "increase": "å­¦æ ¡ãƒ»ç—…é™¢ãªã©å…¬å…±ç³»æ–½è¨­ãŒå¢—ãˆã‚‹ï¼ˆå°ä¸­å­¦æ ¡æ–°è¨­ã€ç—…é™¢é–‹è¨­ã€å¤§å­¦ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹èª˜è‡´ï¼‰",
        "decrease": "çµ±å»ƒåˆãƒ»é–‰é–ã§å…¬å…±ç³»æ–½è¨­ãŒæ¸›ã‚‹ï¼ˆå­¦æ ¡çµ±å»ƒåˆã€ç—…é™¢é–‰é–ï¼‰"
    },
    "employment": {
        "increase": "æ–°è¦é›‡ç”¨å‰µå‡ºãƒ»å¤§è¦æ¨¡æ¡ç”¨ï¼ˆå·¥å ´ç¨¼åƒã€ç‰©æµæ‹ ç‚¹é–‹è¨­ã€äº‹æ¥­æ‹¡å¼µï¼‰",
        "decrease": "äº‹æ¥­æ‰€æ’¤é€€ãƒ»è§£é›‡ã§é›‡ç”¨ãŒæ¸›ã‚‹ï¼ˆäº‹æ¥­æ‰€é–‰é–ã€å·¥å ´æ’¤é€€ï¼‰"
    },
    "disaster": {
        "increase": "ç½å®³ç™ºç”Ÿã‚„è¢«å®³æ‹¡å¤§ã«ã‚ˆã‚Šé­…åŠ›ãŒä½ä¸‹ï¼ˆæ´ªæ°´ãƒ»åœ°éœ‡è¢«å®³ã€åœŸç ‚ç½å®³ï¼‰",
        "decrease": "å¾©æ—§ãƒ»æ²»æ°´ãƒ»è€éœ‡åŒ–ç­‰ã§è¢«å®³ãƒªã‚¹ã‚¯ãŒä¸‹ãŒã‚‹ï¼ˆå ¤é˜²æ•´å‚™ã€æ²³å·æ”¹ä¿®ã€è€éœ‡åŒ–ï¼‰"
    }
}

# åŠ¹æœã®å¼·ã•ã¨æ–¹å‘ã®è¡¨ç¤º
EFFECT_STRENGTH = {
    "housing": {"increase": "å¼±", "decrease": "å¼·"},
    "commercial": {"increase": "å¼·", "decrease": "ä¸­"},
    "transit": {"increase": "å¼±", "decrease": "ä¸­"},
    "policy_boundary": {"increase": "ä¸­", "decrease": "ä¸­"},
    "public_edu_medical": {"increase": "ãªã—", "decrease": "ãªã—"},
    "employment": {"increase": "ä¸­", "decrease": "ä¸­"},
    "disaster": {"increase": "ä¸­", "decrease": "ä¸­"}
}

scenario_details = {
    "ç”ºä¸": town,
    "åŸºæº–å¹´": 2025,
    "äºˆæ¸¬æœŸé–“": "1-3å¹´å…ˆ",
    "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—": event_type_display,
    "å¹´ã‚ªãƒ•ã‚»ãƒƒãƒˆ": "1å¹´ï¼ˆç¿Œå¹´ï¼‰",
    "ä¿¡é ¼åº¦": "1.0",
    "å¼·åº¦": "1.0",
    "æ‰‹å‹•åŠ ç®—": f"h1={h1}äºº, h2={h2}äºº, h3={h3}äººï¼ˆå›ºå®šå€¤ï¼‰",
    "å¼·åº¦è¨­å®š": "å­¦ç¿’ã•ã‚ŒãŸå¼·åº¦ï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰"
}

for key, value in scenario_details.items():
    st.write(f"**{key}**: {value}")

# ã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°èª¬æ˜ã‚’è¡¨ç¤º
st.subheader("ğŸ“‹ é¸æŠã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°")
event_key = f"{event_type}_{effect_direction}"
event_description = EVENT_DESCRIPTIONS[event_type][effect_direction]
effect_strength = EFFECT_STRENGTH[event_type][effect_direction]

col1, col2 = st.columns([2, 1])
with col1:
    st.write(f"**èª¬æ˜**: {event_description}")
with col2:
    st.write(f"**æ¨å®šåŠ¹æœ**: {effect_strength}")

st.markdown("---")

# äºˆæ¸¬å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.header("ğŸ“Š äºˆæ¸¬å®Ÿè¡Œ")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸš€ äºˆæ¸¬å®Ÿè¡Œ", type="primary", use_container_width=True):
    try:
        # ã‚·ãƒŠãƒªã‚ªä½œæˆï¼ˆå¹´æ¬¡åˆ¥å¼·åº¦ã‚’ä½¿ç”¨ï¼‰
        try:
            # å¹´æ¬¡åˆ¥å¼·åº¦ã‚’ä½¿ç”¨
            generator = LearnedScenarioGenerator()
            scenario = generator.create_learned_scenario_with_yearly_intensity(town, event_type, effect_direction)
            scenario["manual_delta"] = {"h1": h1, "h2": h2, "h3": h3}
            
            # å¹´æ¬¡åˆ¥å¼·åº¦ã‚’è¡¨ç¤º
            st.info(f"ğŸ¤– å¹´æ¬¡åˆ¥å¼·åº¦ãŒé©ç”¨ã•ã‚Œã¾ã—ãŸ:")
            for i, event in enumerate(scenario["events"]):
                year_name = ["1å¹´ç›®", "2å¹´ç›®", "3å¹´ç›®"][i]
                st.info(f"  {year_name}: intensity={event['intensity']:.3f}, lag_t={event['lag_t']:.3f}, lag_t1={event['lag_t1']:.3f}")
            
        except Exception as e:
            st.warning(f"âš ï¸ å¹´æ¬¡åˆ¥å¼·åº¦ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼·åº¦ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼·åº¦
            scenario = {
                "town": town,
                "base_year": 2025,
                "horizons": [1, 2, 3],
                "events": [{
                    "year_offset": 1,
                    "event_type": event_type,
                    "effect_direction": effect_direction,
                    "confidence": 1.0,
                    "intensity": 1.0,
                    "lag_t": 1,
                    "lag_t1": 1,
                    "note": f"{event_type} ({effect_direction})"
                }],
                "macros": {},
                "manual_delta": {"h1": h1, "h2": h2, "h3": h3}
            }
        
        # äºˆæ¸¬å®Ÿè¡Œï¼ˆCLIã¨åŒã˜ãƒ•ãƒ­ãƒ¼ï¼‰
        with st.spinner("äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å°‚ç”¨ï¼‰
            output_dir = Path("output")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # Step 1: å°†æ¥ã‚¤ãƒ™ãƒ³ãƒˆè¡Œåˆ—ã®ç”Ÿæˆ
            st.info("Step 1: å°†æ¥ã‚¤ãƒ™ãƒ³ãƒˆè¡Œåˆ—ã‚’ç”Ÿæˆä¸­...")
            future_events = scenario_to_events(scenario)
            future_events.to_csv(output_dir / "l5_future_events.csv", index=False)
            
            # Layer5ã®æ¨™æº–ãƒ‘ã‚¹ã«ã‚‚ä¿å­˜
            layer5_events_path = Path("../../data/processed/l5_future_events.csv")
            future_events.to_csv(layer5_events_path, index=False)
            
            # Step 2: åŸºæº–å¹´ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            st.info("Step 2: åŸºæº–å¹´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")
            baseline = prepare_baseline(town, 2025)
            baseline.to_csv(output_dir / "l5_baseline.csv", index=False)
            
            # Layer5ã®æ¨™æº–ãƒ‘ã‚¹ã«ã‚‚ä¿å­˜
            layer5_baseline_path = Path("../../data/processed/l5_baseline.csv")
            baseline.to_csv(layer5_baseline_path, index=False)
            
            # Step 3: å°†æ¥ç‰¹å¾´ã®æ§‹ç¯‰
            st.info("Step 3: å°†æ¥ç‰¹å¾´ã‚’æ§‹ç¯‰ä¸­...")
            future_features = build_future_features(baseline, future_events, scenario)
            future_features.to_csv(output_dir / "l5_future_features.csv", index=False)
            
            # Layer5ã®æ¨™æº–ãƒ‘ã‚¹ã«ã‚‚ä¿å­˜ï¼ˆforecast_service.pyãŒèª­ã¿è¾¼ã‚€ãŸã‚ï¼‰
            layer5_features_path = Path("../../data/processed/l5_future_features.csv")
            future_features.to_csv(layer5_features_path, index=False)
            
            # Step 4: äººå£äºˆæ¸¬ã®å®Ÿè¡Œ
            st.info("Step 4: äººå£äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
            base_population = baseline["pop_total"].iloc[0] if "pop_total" in baseline.columns else 0.0
            if pd.isna(base_population):
                st.warning("ãƒ™ãƒ¼ã‚¹äººå£ãŒä¸æ˜ã®ãŸã‚ã€0ã‚’ä½¿ç”¨ã—ã¾ã™")
                base_population = 0.0
            
            # æ‰‹å‹•åŠ ç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã§æº–å‚™
            manual_add = {1: float(h1), 2: float(h2), 3: float(h3)}
            
            result = forecast_population(town, 2025, [1, 2, 3], base_population, str(output_dir), manual_add)
        
        # çµæœè¡¨ç¤º
        st.success("âœ… äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # åŸºæœ¬æƒ…å ±
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç”ºä¸", result["town"])
        with col2:
            st.metric("åŸºæº–å¹´", result["base_year"])
        with col3:
            st.metric("äºˆæ¸¬æœŸé–“", f"{min(result['horizons'])}-{max(result['horizons'])}å¹´å…ˆ")

        st.markdown("---")

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        path_df = pd.DataFrame(result["path"])
        explain = result.get("explain", {})

        # ==== å¾©å…ƒãƒã‚§ãƒƒã‚¯ï¼ˆdelta_hat â‰ delta_noexp + exp_people_totalï¼‰ ====
        if explain:
            eps = 1e-6
            _cons_rows = []
            for y in sorted(explain.keys()):
                e = explain[y]
                residual = float(e["delta_hat"]) - (float(e["delta_noexp"]) + float(e["exp_people_total"]))
                _cons_rows.append({"å¹´": y, "Î”å¾©å…ƒèª¤å·®": residual})
            df_cons = pd.DataFrame(_cons_rows)
            if df_cons["Î”å¾©å…ƒèª¤å·®"].abs().max() <= eps:
                st.success("âœ… å¾©å…ƒãƒã‚§ãƒƒã‚¯OKï¼šÎ” = éã‚¤ãƒ™ãƒ³ãƒˆæˆåˆ† + æœŸå¾…åŠ¹æœï¼ˆç‡+æ‰‹å‹•ï¼‰")
            else:
                st.warning("âš ï¸ å¾©å…ƒãƒã‚§ãƒƒã‚¯NGï¼šä¸€éƒ¨ã®å¹´ã§ Î” ãŒåˆæˆã¨ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ï¼ˆä¸‹è¡¨ã‚’ç¢ºèªï¼‰")
                st.dataframe(df_cons, use_container_width=True)

        # ==== æœŸå¾…åŠ¹æœã®å†…è¨³ãƒ†ãƒ¼ãƒ–ãƒ« ====
        st.subheader("æœŸå¾…åŠ¹æœã®å†…è¨³ï¼ˆç‡â†’äººæ•°æ›ç®— + æ‰‹å‹•ï¼‰")
        _rows = []
        for y in sorted(explain.keys()):
            e = explain[y]
            _rows.append({
                "å¹´": y,
                "æœŸå¾…åŠ¹æœï¼ˆç‡ï¼‰": f"{e['exp_rate_terms']*100:.2f}%",
                "æ¯æ•°": float(e["base_pop_for_rate"]),
                "äººæ•°æ›ç®—ï¼ˆç‡Ã—æ¯æ•°ï¼‰": float(e["exp_people_from_rate"]),
                "æ‰‹å‹•äººæ•°": float(e["exp_people_manual"]),
                "åˆè¨ˆï¼ˆç‡+æ‰‹å‹•ï¼‰": float(e["exp_people_total"]),
                "éã‚¤ãƒ™ãƒ³ãƒˆæˆåˆ†": float(e["delta_noexp"]),
                "å¾©å…ƒÎ”": float(e["delta_hat"]),
            })
        if _rows:
            df_explain = pd.DataFrame(_rows).sort_values("å¹´")
            st.dataframe(df_explain, use_container_width=True)
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆUTF-8-SIG ã§Exceläº’æ›ï¼‰
            _csv = df_explain.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "å†…è¨³CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=_csv,
                file_name="explain_summary.csv",
                mime="text/csv",
                type="secondary",
                use_container_width=True
            )

        # ==== ã‚µãƒãƒªãƒ¼ï¼ˆç‡ç”±æ¥åˆè¨ˆ/æ‰‹å‹•åˆè¨ˆ/åˆè¨ˆï¼‰ ====
        sum_rate_people   = float(sum(float(explain[y]["exp_people_from_rate"]) for y in explain))
        sum_manual_people = float(sum(float(explain[y]["exp_people_manual"])     for y in explain))
        sum_total_exp     = float(sum_rate_people + sum_manual_people)
        c1, c2, c3 = st.columns(3)
        with c1: st.metric("ç‡ç”±æ¥åˆè¨ˆ", f"{sum_rate_people:.1f}äºº")
        with c2: st.metric("æ‰‹å‹•åˆè¨ˆ", f"{sum_manual_people:.1f}äºº")
        with c3: st.metric("æœŸå¾…åŠ¹æœ åˆè¨ˆ", f"{sum_total_exp:.1f}äºº")

        st.markdown("---")

        # äººå£äºˆæ¸¬ã®æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•
        st.subheader("ğŸ“ˆ äººå£äºˆæ¸¬ãƒ‘ã‚¹")

        fig_pop = go.Figure()

        # äººå£ãƒ‘ã‚¹ï¼ˆç·šï¼‰
        fig_pop.add_trace(go.Scatter(
            x=path_df["year"],
            y=path_df["pop_hat"],
            mode='lines+markers',
            name='äºˆæ¸¬äººå£',
            line=dict(color='#1f77b4', width=3),
            marker=dict(size=10, color='#1f77b4')
        ))

        # ä¿¡é ¼åŒºé–“ï¼ˆå¸¯ï¼‰
        if "pi95_pop" in path_df.columns:
            lower = [p[0] if isinstance(p, list) else p for p in path_df["pi95_pop"]]
            upper = [p[1] if isinstance(p, list) else p for p in path_df["pi95_pop"]]
            
            fig_pop.add_trace(go.Scatter(
                x=path_df["year"].tolist() + path_df["year"].tolist()[::-1],
                y=upper + lower[::-1],
                fill='tonexty',
                fillcolor='rgba(31, 119, 180, 0.2)',
                line=dict(color='rgba(255,255,255,0)'),
                name='95%ä¿¡é ¼åŒºé–“',
                showlegend=True
            ))

        fig_pop.update_layout(
            title=f"äººå£äºˆæ¸¬ãƒ‘ã‚¹: {result['town']} (åŸºæº–å¹´: {result['base_year']})",
            xaxis_title="å¹´",
            yaxis_title="äººå£ï¼ˆäººï¼‰",
            hovermode='x unified',
            template="plotly_white",
            height=500
        )

        st.plotly_chart(fig_pop, use_container_width=True)

        # äººå£å¤‰åŒ–é‡ã®ã‚°ãƒ©ãƒ•
        st.subheader("ğŸ“Š äººå£å¤‰åŒ–é‡ï¼ˆÎ”äººå£ï¼‰")

        fig_delta = go.Figure()

        # ãƒ›ãƒãƒ¼ã« "ç‡ãƒ»æ¯æ•°ãƒ»äººæ•°æ›ç®—ãƒ»æ‰‹å‹•" ã‚’è¿½åŠ 
        custom = []
        for y in path_df["year"]:
            e = explain.get(y, {"exp_rate_terms": 0.0, "base_pop_for_rate": 0.0,
                                "exp_people_from_rate": 0.0, "exp_people_manual": 0.0})
            custom.append([e["exp_rate_terms"], e["base_pop_for_rate"], e["exp_people_from_rate"], e["exp_people_manual"]])

        # Î”äººå£ã®ãƒãƒ¼
        fig_delta.add_trace(go.Bar(
            x=path_df["year"],
            y=path_df["delta_hat"],
            name='Î”äººå£',
            marker_color=['#ff7f0e' if x > 0 else '#d62728' for x in path_df["delta_hat"]],
            text=[f"{x:+.1f}" for x in path_df["delta_hat"]],
            textposition='auto',
            customdata=custom,
            hovertemplate=(
                "å¹´ %{x}<br>"
                "Î”äººæ•°: %{y:.2f}<br>"
                "æœŸå¾…åŠ¹æœ(ç‡): %{customdata[0]:.4f}ï¼ˆ= %{customdata[0]:.2%}ï¼‰<br>"
                "æ¯æ•°: %{customdata[1]:.1f}<br>"
                "äººæ•°æ›ç®—: %{customdata[2]:.2f}<br>"
                "æ‰‹å‹•äººæ•°: %{customdata[3]:.2f}<extra></extra>"
            )
        ))

        # ä¿¡é ¼åŒºé–“
        if "pi95_delta" in path_df.columns:
            lower_delta = [p[0] if isinstance(p, list) else p for p in path_df["pi95_delta"]]
            upper_delta = [p[1] if isinstance(p, list) else p for p in path_df["pi95_delta"]]
            
            fig_delta.add_trace(go.Scatter(
                x=path_df["year"],
                y=upper_delta,
                mode='markers',
                marker=dict(color='red', size=8, symbol='triangle-up'),
                name='95%ä¿¡é ¼åŒºé–“ä¸Šé™',
                showlegend=True
            ))
            
            fig_delta.add_trace(go.Scatter(
                x=path_df["year"],
                y=lower_delta,
                mode='markers',
                marker=dict(color='red', size=8, symbol='triangle-down'),
                name='95%ä¿¡é ¼åŒºé–“ä¸‹é™',
                showlegend=True
            ))

        fig_delta.update_layout(
            title="å¹´åˆ¥äººå£å¤‰åŒ–é‡",
            xaxis_title="å¹´",
            yaxis_title="äººå£å¤‰åŒ–é‡ï¼ˆäººï¼‰",
            template="plotly_white",
            height=400
        )

        st.plotly_chart(fig_delta, use_container_width=True)
        st.caption("ã‚°ãƒ©ãƒ•ã«ãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼ã™ã‚‹ã¨ã€Œç‡ãƒ»æ¯æ•°ãƒ»äººæ•°æ›ç®—ãƒ»æ‰‹å‹•ã€ã®å†…è¨³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

        # å¯„ä¸åˆ†è§£ã®ã‚°ãƒ©ãƒ•
        st.subheader("ğŸ¥§ å¯„ä¸åˆ†è§£")

        # å¯„ä¸ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        contrib_data = []
        for _, row in path_df.iterrows():
            contrib = row["contrib"]
            contrib_data.append({
                "year": row["year"],
                "exp": contrib.get("exp", 0),
                "macro": contrib.get("macro", 0),
                "inertia": contrib.get("inertia", 0),
                "other": contrib.get("other", 0),
                "delta_hat": row["delta_hat"]
            })

        contrib_df = pd.DataFrame(contrib_data)

        # å¯„ä¸åˆ†è§£ã®ç©ã¿ä¸Šã’ãƒãƒ¼
        fig_contrib = go.Figure()

        colors = {
            "exp": "#FF6B6B",      # èµ¤ï¼ˆæœŸå¾…åŠ¹æœï¼‰
            "macro": "#4ECDC4",    # é’ç·‘ï¼ˆãƒã‚¯ãƒ­ï¼‰
            "inertia": "#45B7D1",  # é’ï¼ˆæ…£æ€§ï¼‰
            "other": "#96CEB4"     # ç·‘ï¼ˆãã®ä»–ï¼‰
        }

        for col in ["exp", "macro", "inertia", "other"]:
            fig_contrib.add_trace(go.Bar(
                x=contrib_df["year"],
                y=contrib_df[col],
                name=col,
                marker_color=colors[col],
                opacity=0.8
            ))

        fig_contrib.update_layout(
            title="å¯„ä¸åˆ†è§£ï¼ˆç©ã¿ä¸Šã’ãƒãƒ¼ï¼‰",
            xaxis_title="å¹´",
            yaxis_title="å¯„ä¸ï¼ˆäººï¼‰",
            barmode='relative',
            template="plotly_white",
            height=500
        )

        st.plotly_chart(fig_contrib, use_container_width=True)

        # å¹´åˆ¥å¯„ä¸åˆ†è§£ã®å††ã‚°ãƒ©ãƒ•
        st.subheader("ğŸ¥§ å¹´åˆ¥å¯„ä¸åˆ†è§£ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")

        selected_year = st.selectbox("å¹´ã‚’é¸æŠ", path_df["year"].tolist())

        year_data = path_df[path_df["year"] == selected_year].iloc[0]
        contrib = year_data["contrib"]

        # å††ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿
        labels = []
        values = []
        colors_pie = []

        for key, value in contrib.items():
            if abs(value) > 0.1:  # 0ã«è¿‘ã„å€¤ã¯é™¤å¤–
                labels.append(key)
                values.append(abs(value))
                colors_pie.append(colors.get(key, "#CCCCCC"))

        fig_pie = go.Figure(data=[go.Pie(
            labels=labels,
            values=values,
            marker_colors=colors_pie,
            textinfo='label+percent+value',
            texttemplate='%{label}<br>%{percent}<br>(%{value:.1f}äºº)'
        )])

        fig_pie.update_layout(
            title=f"å¯„ä¸åˆ†è§£: {selected_year}å¹´",
            template="plotly_white",
            height=400
        )

        st.plotly_chart(fig_pie, use_container_width=True)

        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿")

        # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æº–å‚™
        display_df = path_df.copy()
        display_df["äººå£"] = display_df["pop_hat"].round(1)
        display_df["Î”äººå£"] = display_df["delta_hat"].round(1)
        display_df["æœŸå¾…åŠ¹æœ"] = display_df["contrib"].apply(lambda x: x.get("exp", 0)).round(1)
        display_df["ãƒã‚¯ãƒ­"] = display_df["contrib"].apply(lambda x: x.get("macro", 0)).round(1)
        display_df["æ…£æ€§"] = display_df["contrib"].apply(lambda x: x.get("inertia", 0)).round(1)
        display_df["ãã®ä»–"] = display_df["contrib"].apply(lambda x: x.get("other", 0)).round(1)
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆå†…è¨³é€æ˜åŒ–ï¼‰
        try:
            debug_detail_path = Path(f"output/l5_debug_detail_{town.replace(' ', '_')}.csv")
            if debug_detail_path.exists():
                debug_detail_df = pd.read_csv(debug_detail_path)
                
                # å†…è¨³æƒ…å ±ã‚’è¿½åŠ 
                if not debug_detail_df.empty:
                    # åˆ—åã‚’ç¢ºèªã—ã¦é©åˆ‡ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                    year_col = "year" if "year" in debug_detail_df.columns else "å¹´"
                    
                    # å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    required_cols = [year_col, "exp_people_from_rate", "exp_people_manual", "exp_people_total"]
                    available_cols = [col for col in required_cols if col in debug_detail_df.columns]
                    
                    if len(available_cols) >= 2:  # å¹´åˆ—ã¨å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ‡ãƒ¼ã‚¿åˆ—ãŒå¿…è¦
                        # å¹´ã§ãƒãƒ¼ã‚¸
                        merged_df = display_df.merge(
                            debug_detail_df[available_cols], 
                            left_on="year", 
                            right_on=year_col, 
                            how="left"
                        )
                    else:
                        st.warning(f"ãƒ‡ãƒãƒƒã‚°è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(debug_detail_df.columns)}")
                        merged_df = display_df
                    
                    # å†…è¨³åˆ—ã‚’è¿½åŠ 
                    merged_df["æœŸå¾…åŠ¹æœ(ç‡ç”±æ¥)"] = merged_df["exp_people_from_rate"].round(1)
                    merged_df["æœŸå¾…åŠ¹æœ(æ‰‹å‹•)"] = merged_df["exp_people_manual"].round(1)
                    merged_df["æœŸå¾…åŠ¹æœ(åˆè¨ˆ)"] = merged_df["exp_people_total"].round(1)
                    
                    display_df = merged_df
                    
                    # å†…è¨³ã®è¡¨ç¤º
                    st.subheader("ğŸ” æœŸå¾…åŠ¹æœã®å†…è¨³")
                    st.info("æœŸå¾…åŠ¹æœã‚’ã€Œç‡ç”±æ¥ã€ã¨ã€Œæ‰‹å‹•äººæ•°ã€ã«åˆ†ã‘ã¦è¡¨ç¤º")
                    
                    # å†…è¨³ã®ã‚°ãƒ©ãƒ•
                    fig_breakdown = go.Figure()
                    
                    # ç‡ç”±æ¥ã®æœŸå¾…åŠ¹æœ
                    fig_breakdown.add_trace(go.Bar(
                        x=merged_df["year"],
                        y=merged_df["exp_people_from_rate"],
                        name='æœŸå¾…åŠ¹æœ(ç‡ç”±æ¥)',
                        marker_color='#FF6B6B',
                        opacity=0.8
                    ))
                    
                    # æ‰‹å‹•ã®æœŸå¾…åŠ¹æœ
                    fig_breakdown.add_trace(go.Bar(
                        x=merged_df["year"],
                        y=merged_df["exp_people_manual"],
                        name='æœŸå¾…åŠ¹æœ(æ‰‹å‹•)',
                        marker_color='#4ECDC4',
                        opacity=0.8
                    ))
                    
                    fig_breakdown.update_layout(
                        title="æœŸå¾…åŠ¹æœã®å†…è¨³",
                        xaxis_title="å¹´",
                        yaxis_title="å¯„ä¸ï¼ˆäººï¼‰",
                        barmode='stack',
                        template="plotly_white",
                        height=400
                    )
                    
                    st.plotly_chart(fig_breakdown, use_container_width=True)
                    
        except Exception as e:
            st.warning(f"ãƒ‡ãƒãƒƒã‚°è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # ä¿¡é ¼åŒºé–“ã®è¡¨ç¤º
        if "pi95_pop" in display_df.columns:
            display_df["äººå£95%CI"] = display_df["pi95_pop"].apply(
                lambda x: f"[{x[0]:.1f}, {x[1]:.1f}]" if isinstance(x, list) else f"[{x:.1f}, {x:.1f}]"
            )

        if "pi95_delta" in display_df.columns:
            display_df["Î”äººå£95%CI"] = display_df["pi95_delta"].apply(
                lambda x: f"[{x[0]:.1f}, {x[1]:.1f}]" if isinstance(x, list) else f"[{x:.1f}, {x:.1f}]"
            )

        # è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ
        display_columns = ["å¹´", "äººå£", "Î”äººå£", "æœŸå¾…åŠ¹æœ", "ãƒã‚¯ãƒ­", "æ…£æ€§", "ãã®ä»–"]
        
        # å†…è¨³åˆ—ãŒã‚ã‚Œã°è¿½åŠ 
        if "æœŸå¾…åŠ¹æœ(ç‡ç”±æ¥)" in display_df.columns:
            display_columns.extend(["æœŸå¾…åŠ¹æœ(ç‡ç”±æ¥)", "æœŸå¾…åŠ¹æœ(æ‰‹å‹•)", "æœŸå¾…åŠ¹æœ(åˆè¨ˆ)"])
        
        if "äººå£95%CI" in display_df.columns:
            display_columns.append("äººå£95%CI")
        if "Î”äººå£95%CI" in display_df.columns:
            display_columns.append("Î”äººå£95%CI")

        # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        display_df = display_df.rename(columns={
            "year": "å¹´",
            "äººå£": "äººå£",
            "Î”äººå£": "Î”äººå£",
            "æœŸå¾…åŠ¹æœ": "æœŸå¾…åŠ¹æœ",
            "ãƒã‚¯ãƒ­": "ãƒã‚¯ãƒ­",
            "æ…£æ€§": "æ…£æ€§",
            "ãã®ä»–": "ãã®ä»–"
        })

        st.dataframe(display_df[display_columns], use_container_width=True)

        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        st.subheader("ğŸ“Š ã‚µãƒãƒªãƒ¼çµ±è¨ˆ")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            final_pop = path_df["pop_hat"].iloc[-1]
            initial_pop = path_df["pop_hat"].iloc[0]
            total_change = final_pop - initial_pop
            st.metric(
                "ç·äººå£å¤‰åŒ–",
                f"{total_change:.1f}äºº",
                f"{initial_pop:.1f} â†’ {final_pop:.1f}"
            )

        with col2:
            avg_delta = path_df["delta_hat"].mean()
            st.metric(
                "å¹³å‡å¹´æ¬¡å¤‰åŒ–",
                f"{avg_delta:.1f}äºº/å¹´"
            )

        with col3:
            max_exp = path_df["contrib"].apply(lambda x: x.get("exp", 0)).max()
            st.metric(
                "æœ€å¤§æœŸå¾…åŠ¹æœ",
                f"{max_exp:.1f}äºº"
            )

        with col4:
            # explainæ©Ÿèƒ½ã‹ã‚‰æœŸå¾…åŠ¹æœåˆè¨ˆã‚’å–å¾—
            if explain:
                total_exp = sum(explain[y]["exp_people_total"] for y in explain)
            else:
                total_exp = path_df["contrib"].apply(lambda x: x.get("exp", 0)).sum()
            st.metric(
                "æœŸå¾…åŠ¹æœåˆè¨ˆ",
                f"{total_exp:.1f}äºº"
            )
        
        # å†…è¨³ã‚µãƒãƒªãƒ¼ï¼ˆexplainæ©Ÿèƒ½ã‹ã‚‰å–å¾—ï¼‰
        if explain:
            st.subheader("ğŸ” æœŸå¾…åŠ¹æœå†…è¨³ã‚µãƒãƒªãƒ¼")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                total_rate = sum(explain[y]["exp_people_from_rate"] for y in explain)
                st.metric(
                    "ç‡ç”±æ¥åˆè¨ˆ",
                    f"{total_rate:.1f}äºº"
                )
            
            with col2:
                total_manual = sum(explain[y]["exp_people_manual"] for y in explain)
                st.metric(
                    "æ‰‹å‹•åˆè¨ˆ",
                    f"{total_manual:.1f}äºº"
                )
            
            with col3:
                total_combined = sum(explain[y]["exp_people_total"] for y in explain)
                st.metric(
                    "åˆè¨ˆ",
                    f"{total_combined:.1f}äºº"
                )

        # ==== Debug: explainã®ç”ŸJSON ====
        with st.expander("Debug: raw explain JSONï¼ˆé–‹ç™ºç”¨ï¼‰", expanded=False):
            if st.checkbox("è¡¨ç¤ºã™ã‚‹ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰", value=False):
                # å¹´ã‚­ãƒ¼ã‚’ã‚½ãƒ¼ãƒˆã—ã€ã‚µã‚¤ã‚ºã‚’æŠ‘ãˆãŸå½¢ã§å‡ºã™
                _mini = {int(y): {
                    "exp_rate_terms": float(explain[y]["exp_rate_terms"]),
                    "base_pop_for_rate": float(explain[y]["base_pop_for_rate"]),
                    "exp_people_from_rate": float(explain[y]["exp_people_from_rate"]),
                    "exp_people_manual": float(explain[y]["exp_people_manual"]),
                    "exp_people_total": float(explain[y]["exp_people_total"]),
                    "delta_noexp": float(explain[y]["delta_noexp"]),
                    "delta_hat": float(explain[y]["delta_hat"]),
                } for y in sorted(explain.keys())}
                st.json(_mini)

    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.exception(e)

# è¨ˆç®—å¼ã®èª¬æ˜
with st.expander("ğŸ“ è¨ˆç®—å¼ã®èª¬æ˜", expanded=False):
    st.markdown("""
    **æœŸå¾…åŠ¹æœã®è¨ˆç®—å¼:**
    - **æœŸå¾…åŠ¹æœï¼ˆç‡ï¼‰** = ã‚¤ãƒ™ãƒ³ãƒˆç”±æ¥ã®ç‡å¯„ä¸ã®åˆè¨ˆ
    - **äººæ•°æ›ç®—** = æœŸå¾…åŠ¹æœï¼ˆç‡ï¼‰ Ã— æ¯æ•°ï¼ˆé€šå¸¸ã¯å‰å¹´äººå£ï¼‰
    - **åˆè¨ˆï¼ˆç‡+æ‰‹å‹•ï¼‰** = äººæ•°æ›ç®— + æ‰‹å‹•äººæ•°
    - **å¾©å…ƒÎ”** = éã‚¤ãƒ™ãƒ³ãƒˆæˆåˆ† + åˆè¨ˆï¼ˆç‡+æ‰‹å‹•ï¼‰
    
    **å¾©å…ƒãƒã‚§ãƒƒã‚¯:**
    - Î”äººå£ = éã‚¤ãƒ™ãƒ³ãƒˆæˆåˆ† + æœŸå¾…åŠ¹æœï¼ˆç‡+æ‰‹å‹•ï¼‰
    - ã“ã®ç­‰å¼ãŒæˆç«‹ã™ã‚‹ã“ã¨ã‚’å¹´ã”ã¨ã«æ¤œè¨¼
    """)

# ãƒ˜ãƒ«ãƒ—
with st.expander("â“ ãƒ˜ãƒ«ãƒ—"):
    st.markdown("""
    ### ä½¿ç”¨æ–¹æ³•
    
    1. **ç”ºä¸é¸æŠ**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§äºˆæ¸¬å¯¾è±¡ã®ç”ºä¸ã‚’é¸æŠ
    2. **ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š**: ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’é¸æŠï¼ˆå¢—åŠ ãƒ»æ¸›å°‘ã®æ–¹å‘ã¯æ—¢ã«å«ã¾ã‚Œã¦ã„ã¾ã™ï¼‰
    3. **äºˆæ¸¬å®Ÿè¡Œ**: ã€Œäºˆæ¸¬å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    
    ### ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®èª¬æ˜ï¼ˆ11ç¨®é¡ï¼‰
    
    - **ä½å®…ä¾›çµ¦ã®å¢—åŠ ï¼ˆç«£å·¥ï¼‰**: æ–°è¦ã®ãƒãƒ³ã‚·ãƒ§ãƒ³ãƒ»ã‚¢ãƒ‘ãƒ¼ãƒˆãƒ»æˆ¸å»ºã¦ãŒä¾›çµ¦ã•ã‚Œã‚‹ï¼ˆåˆ†è­²ãƒãƒ³ã‚·ãƒ§ãƒ³ç«£å·¥ã€å›£åœ°å…¥å±…ã€å®…åœ°é€ æˆå¾Œã®å…¥å±…ï¼‰
    - **ä½å®…ã®æ¸›å°‘ãƒ»å–ªå¤±**: ä½å®…ã®è§£ä½“ãƒ»ç”¨é€”è»¢ç”¨ãƒ»ç©ºãå®¶åŒ–ãªã©ã§å®Ÿè³ªçš„ãªä¾›çµ¦ãŒæ¸›ã‚‹ï¼ˆä¸€æ–‰è§£ä½“ã€è€æœ½åŒ–ã§æœªåˆ©ç”¨åŒ–ã€ä½å®…â†’é§è»Šå ´è»¢ç”¨ï¼‰
    - **å•†æ¥­æ–½è¨­ã®å¢—åŠ **: åº—èˆ—ãƒ»ãƒ¢ãƒ¼ãƒ«ãªã©å•†æ¥­é›†ç©ãŒæ‹¡å¤§ï¼ˆå¤§å‹å•†æ¥­æ–½è¨­é–‹æ¥­ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼æ–°è¨­ã€å•†åº—é›†ç©ï¼‰
    - **äº¤é€šåˆ©ä¾¿ã®å‘ä¸Š**: æ–°é§…ãƒ»å¢—ä¾¿ãƒ»é“è·¯æ•´å‚™ãªã©ã§ã‚¢ã‚¯ã‚»ã‚¹ãŒæ”¹å–„ï¼ˆæ–°é§…é–‹æ¥­ã€ãƒã‚¹å¢—ä¾¿ã€ICä¾›ç”¨ï¼‰
    - **äº¤é€šåˆ©ä¾¿ã®ä½ä¸‹**: è·¯ç·šæ’¤é€€ãƒ»æ¸›ä¾¿ç­‰ã§ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‚ªåŒ–ï¼ˆãƒã‚¹æ¸›ä¾¿ã€è·¯ç·šå»ƒæ­¢ï¼‰
    - **å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®å¢—åŠ **: å­¦æ ¡ãƒ»ç—…é™¢ãªã©å…¬å…±ç³»æ–½è¨­ãŒå¢—ãˆã‚‹ï¼ˆå°ä¸­å­¦æ ¡æ–°è¨­ã€ç—…é™¢é–‹è¨­ã€å¤§å­¦ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹èª˜è‡´ï¼‰
    - **å…¬å…±ãƒ»æ•™è‚²ãƒ»åŒ»ç™‚ã®æ¸›å°‘**: çµ±å»ƒåˆãƒ»é–‰é–ã§å…¬å…±ç³»æ–½è¨­ãŒæ¸›ã‚‹ï¼ˆå­¦æ ¡çµ±å»ƒåˆã€ç—…é™¢é–‰é–ï¼‰
    - **é›‡ç”¨æ©Ÿä¼šã®å¢—åŠ **: æ–°è¦é›‡ç”¨å‰µå‡ºãƒ»å¤§è¦æ¨¡æ¡ç”¨ï¼ˆå·¥å ´ç¨¼åƒã€ç‰©æµæ‹ ç‚¹é–‹è¨­ã€äº‹æ¥­æ‹¡å¼µï¼‰
    - **é›‡ç”¨æ©Ÿä¼šã®æ¸›å°‘**: äº‹æ¥­æ‰€æ’¤é€€ãƒ»è§£é›‡ã§é›‡ç”¨ãŒæ¸›ã‚‹ï¼ˆäº‹æ¥­æ‰€é–‰é–ã€å·¥å ´æ’¤é€€ï¼‰
    - **ç½å®³è¢«å®³ãƒ»ãƒªã‚¹ã‚¯ã®å¢—åŠ **: ç½å®³ç™ºç”Ÿã‚„è¢«å®³æ‹¡å¤§ã«ã‚ˆã‚Šé­…åŠ›ãŒä½ä¸‹ï¼ˆæ´ªæ°´ãƒ»åœ°éœ‡è¢«å®³ã€åœŸç ‚ç½å®³ï¼‰
    - **ç½å®³ãƒªã‚¹ã‚¯ã®ä½ä¸‹ï¼ˆé˜²ç½æ•´å‚™ï¼‰**: å¾©æ—§ãƒ»æ²»æ°´ãƒ»è€éœ‡åŒ–ç­‰ã§è¢«å®³ãƒªã‚¹ã‚¯ãŒä¸‹ãŒã‚‹ï¼ˆå ¤é˜²æ•´å‚™ã€æ²³å·æ”¹ä¿®ã€è€éœ‡åŒ–ï¼‰
    
    
    ### å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    - åŸºæº–å¹´: 2025å¹´
    - äºˆæ¸¬æœŸé–“: 1-3å¹´å…ˆ
    - å¹´ã‚ªãƒ•ã‚»ãƒƒãƒˆ: 1å¹´ï¼ˆç¿Œå¹´ï¼‰
    - ä¿¡é ¼åº¦: 1.0
    - å¼·åº¦: æ©Ÿæ¢°å­¦ç¿’ã§è‡ªå‹•æœ€é©åŒ–
    - æ‰‹å‹•åŠ ç®—: 0ã«å›ºå®šï¼ˆç´”ç²‹ãªã‚¤ãƒ™ãƒ³ãƒˆåŠ¹æœã‚’ç¢ºèªã™ã‚‹ãŸã‚ï¼‰
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
    st.sidebar.markdown("---")
    st.sidebar.caption("Â© 2023 åœ°åŸŸç§‘å­¦ç ”ç©¶æ‰€")
